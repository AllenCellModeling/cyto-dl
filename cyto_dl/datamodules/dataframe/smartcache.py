from pathlib import Path
from typing import Dict, Optional, Union

import dask
import numpy as np
import pandas as pd
from aicsimageio import AICSImage
from dask.diagnostics import ProgressBar
from lightning import LightningDataModule
from monai.data import DataLoader
from monai.data.dataset import Dataset, SmartCacheDataset
from monai.transforms import Compose
from omegaconf import DictConfig
from sklearn.model_selection import train_test_split


class SmartcacheDatamodule(LightningDataModule):
    """Datamodule for large CZI datasets that don't fit in memory."""

    def __init__(
        self,
        csv_path: Union[Path, str],
        transforms: Compose = None,
        img_data: Optional[Dict[str, Union[Path, str]]] = None,
        n_val: int = 20,
        pct_val: float = 0.1,
        img_path_column: str = "raw",
        channel_column: str = "ch",
        spatial_dims: int = 3,
        neighboring_timepoints: bool = False,
        num_workers: int = 4,
        cache_rate: float = 0.5,
        **kwargs,
    ):
        """
        Parameters
        ----------
        csv_path: Union[Path, str]
            path to csv with image in `img_path_column` and channel in `channel_column`
        transforms: Compose
            Monai transforms to apply to each image. Should start with a transform that uses AICSimageio for image reading
        img_data: Optional[Dict[str, Union[Path, str]]] = None
            Dictionary with 'train' and 'val' keys whose values are csv_path generated by get_per_file_args that enumerates
            scenes and timepoints for each row in csv_path
        n_val: int
            number of validation images to use. Minimum of pct_val * n_images and n_val is used.
        pct_val: float
            percentage of images to use for validation. Minimum of pct_val * n_images and n_val is used.
        img_path_column: str
            column in csv_path that contains the path to the image
        channel_column: str
            column in csv_path that contains the channel to use
        spatial_dims: int
            number of spatial dimensions in the image
        neighboring_timepoints: bool
            whether to return T and T+1 as a 2 channel image, useful for models incorporating time
        num_workers: int
            number of workers to use for loading data. Most be specified here to schedule replacement workers for cache data
        cache_rate: float
            percentage of data to cache
        """
        super().__init__()
        self.csv_path = Path(csv_path)
        (self.csv_path.parents[0] / "loaded_data").mkdir(exist_ok=True, parents=True)
        # read img_data if it's a dict, otherwise set to empty dict
        if isinstance(img_data, (dict, DictConfig)):
            self.img_data = {
                k: [row._asdict() for row in pd.read_csv(v).itertuples()]
                for k, v in img_data.items()
            }
        else:
            self.img_data = {}
            self.df = pd.read_csv(csv_path)
            val_size = np.min([n_val, int(len(self.df) * pct_val)])
            self.val_size = np.max([val_size, 1])

        self.num_workers = num_workers
        self.kwargs = kwargs

        self.datasets = {}
        self.img_path_column = img_path_column
        self.channel_column = channel_column
        self.spatial_dims = spatial_dims
        self.transforms = transforms
        self.neighboring_timepoints = neighboring_timepoints
        self.cache_rate = cache_rate

    def _get_scenes(self, img):
        """Get the number of scenes in an image."""
        return img.scenes

    def _get_timepoints(self, img):
        """Get the number of timepoints in an image."""
        timepoints = list(range(img.dims.T))
        if self.neighboring_timepoints:
            return timepoints[:-1]
        return timepoints

    @dask.delayed
    def _get_file_args(self, row):
        row = row._asdict()
        img = AICSImage(row[self.img_path_column])
        scenes = self._get_scenes(img)
        timepoints = self._get_timepoints(img)
        img_data = []

        for scene in scenes:
            for timepoint in timepoints:
                img_data.append(
                    {
                        "dimension_order_out": "ZYX"[-self.spatial_dims :]
                        if not self.neighboring_timepoints
                        else "T" + "ZYX"[-self.spatial_dims :],
                        "C": row[self.channel_column],
                        "scene": scene,
                        "T": timepoint
                        if not self.neighboring_timepoints
                        else [timepoint, timepoint + 1],
                        "original_path": row[self.img_path_column],
                        "physical_pixel_dims": ",".join(
                            [str(x) for x in img.physical_pixel_sizes]
                        ),
                    }
                )
        return img_data

    def get_per_file_args(self, df):
        """Parallelize getting the image loading arguments enumerating all
        timepoints/channels/scenes for each file in the dataframe."""
        with ProgressBar():
            img_data = dask.compute(*[self._get_file_args(row) for row in df.itertuples()])
        img_data = [item for sublist in img_data for item in sublist]
        return img_data

    def prepare_data(self):
        pass

    def setup(self, stage=None):
        if stage == "fit":
            if self.img_data == {}:
                # split df into train/test/val
                img_data = self.get_per_file_args(self.df)
                self.img_data["train"], self.img_data["valid"] = train_test_split(
                    img_data, test_size=self.val_size
                )
                # generating per_file_args can take a while, save it out
                pd.DataFrame(self.img_data["train"]).to_csv(
                    f"{self.csv_path.parents[0]}/loaded_data/train_img_data.csv"
                )
                pd.DataFrame(self.img_data["valid"]).to_csv(
                    f"{self.csv_path.parents[0]}/loaded_data/val_img_data.csv"
                )
            self.datasets["train"] = SmartCacheDataset(
                self.img_data["train"],
                transform=self.transforms["train"],
                cache_rate=self.cache_rate,
                num_replace_workers=self.num_workers // 2,
            )
            self.datasets["valid"] = SmartCacheDataset(
                self.img_data["valid"],
                transform=self.transforms["valid"],
                cache_rate=1.0,
                num_replace_workers=1,
            )

        elif stage in ("test", "predict"):
            self.img_data[stage] = self.get_per_file_args(self.df)
            self.datasets[stage] = Dataset(self.img_data[stage], transform=self.transforms[stage])

    def make_dataloader(self, split):
        # smartcachedataset can't have persistent workers
        self.kwargs["persistent_workers"] = split not in ("train", "valid")
        if "num_workers" in self.kwargs:
            del self.kwargs["num_workers"]

        return DataLoader(
            self.datasets[split],
            num_workers=self.num_workers // 2,
            **self.kwargs,
        )

    def train_dataloader(self):
        return self.make_dataloader("train")

    def val_dataloader(self):
        return self.make_dataloader("valid")

    def test_dataloader(self):
        return self.make_dataloader("test")

    def predict_dataloader(self):
        return self.make_dataloader("predict")
