_target_: cyto_dl.models.im2im.MultiTaskIm2Im

save_images_every_n_epochs: 1
save_dir: ${paths.output_dir}

x_key: ${source_col}

backbone:
  _target_: cyto_dl.nn.vits.mae.HieraMAE
  spatial_dims: ${spatial_dims}
  patch_size: 2 # patch_size * num_patches should be your image shape (data._aux.patch_shape)
  num_patches: 8 # patch_size * num_patches = img_shape
  num_mask_units: 4 #Mask units are used for local attention. img_shape / num_mask_units = size of each mask unit in pixels, num_patches/num_mask_units = number of patches permask unit
  emb_dim: 4
  # NOTE: this is a very small model for testing - for best performance, the downsampling ratios, embedding dimension, number of layers and number of heads should be adjusted to your data
  architecture:
    # mask_unit_attention blocks - attention is only done within a mask unit and not across mask units
    # the total amount of q_stride across the architecture must be less than the number of patches per mask unit
    - repeat: 1 # number of times to repeat this block
      q_stride: 2 # size of downsampling within a mask unit
      num_heads: 1
    - repeat: 1
      q_stride: 1
      num_heads: 2
    # self attention transformer - attention is done across all patches, irrespective of which mask unit they're in
    - repeat: 2
      num_heads: 4
      self_attention: True
  decoder_layer: 1
  decoder_dim: 16
  mask_ratio: 0.66666666666
  context_pixels: 3
  use_crossmae: True

task_heads: ${kv_to_dict:${model._aux._tasks}}

optimizer:
  generator:
    _partial_: True
    _target_: torch.optim.AdamW
    weight_decay: 0.05

lr_scheduler:
  generator:
    _partial_: True
    _target_: torch.optim.lr_scheduler.OneCycleLR
    max_lr: 0.0001
    epochs: ${trainer.max_epochs}
    steps_per_epoch: 1
    pct_start: 0.1

inference_args:
  sw_batch_size: 1
  roi_size: ${data._aux.patch_shape}
  overlap: 0
  progress: True
  mode: "gaussian"

_aux:
  _tasks:
    - - ${source_col}
      - _target_: cyto_dl.nn.head.mae_head.MAEHead
        loss:
        postprocess:
          input:
            _target_: cyto_dl.models.im2im.utils.postprocessing.ActThreshLabel
            rescale_dtype: numpy.uint8
          prediction:
            _target_: cyto_dl.models.im2im.utils.postprocessing.ActThreshLabel
            rescale_dtype: numpy.uint8
