# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: patch.yaml
  - override /model: multitask.yaml
  - override /callbacks: default.yaml
  - override /trainer: gpu.yaml
  - override /logger: mlflow_im2im.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["dev"]
seed: 12345

trainer:
  max_epochs: 100
  check_val_every_n_epoch: 1

callbacks:
  early_stopping:
    monitor: val_loss
  model_checkpoint:
    dirpath: ${paths.output_dir}/ckpts
    monitor: val_loss
    save_top_k: 5
    every_n_epochs: 1

datamodule:
  path: //allen/aics/assay-dev/users/Benji/InactiveProjects/FBL_mitosis/1x_erode_and_hysteresis/hard_train
  cache_dir: //allen/aics/assay-dev/users/Benji/InactiveProjects/FBL_mitosis/1x_erode_and_hysteresis/hard_train/cache
  subsample: 
    train: 1
    test: 1
    valid: 1

logger:
  mlflow_im2im:
    experiment_name: benji_im2im_serotiny_port
    run_name: mlflogger_test