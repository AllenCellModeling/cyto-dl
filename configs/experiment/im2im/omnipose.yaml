# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: im2im/omnipose.yaml
  - override /model: im2im/omnipose.yaml
  - override /callbacks: default.yaml
  - override /trainer: gpu.yaml
  - override /logger: mlflow.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["dev"]
seed: 12345

experiment_name: benji_omnipose
run_name: test
source_col: YOUR_SOURCE_COLUMN_NAME
target_col: YOUR_TARGET_COLUMN_NAME
persist_cache: True

trainer:
  max_epochs: 1000
  check_val_every_n_epoch: 1
  accelerator: "gpu"
  devices:

model:
  patch_shape: [32, 256, 256]

data:
  path: ${paths.data_dir}/omnipose
  cache_dir: ${paths.data_dir}/omnipose/cache
  batch_size: 1
  subsample:
    train: 2
    valid: 2
    test: 2

##### ONLY USE WITH A100s
extras:
  precision:
    _target_: torch.set_float32_matmul_precision
    precision: medium
